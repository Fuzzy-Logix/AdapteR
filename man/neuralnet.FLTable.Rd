% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FLNNet.R
\name{neuralnet.FLTable}
\alias{neuralnet.FLTable}
\title{\code{neuralnet} performs Neural Network on FLTable objects.
The DB Lytix function called is FLNNetUDT. Artificial neural networks are a family
of statistical learning algorithms inspired by biological neural networks
and are used to estimate or approximate transformations that depend on a
large number of inputs. Thesetransformation are then used to model the output.
In DB Lytix, neural network is implemented as a user-defined table function which takes
the input in deep format, the topography of the network along with some
hyper-parameters to calculate the neuron connection weights using the
back-propagation algorithm.}
\usage{
\method{plot}{FLNnet}(formula, data, fetchID = TRUE, hidden = 5,
  layers = 2, learningrate = 0.2, epoch = 500, IsSigmoid = 1, ...)
}
\arguments{
\item{formula}{A symbolic description of model to be fitted}

\item{data}{An object of class FLTable.}

\item{hidden}{Number of neurons in the hidden layer}

\item{layers}{Number of layers of Neural Net model as of now at Max 2 are alloed.}

\item{epoch}{Maximum number of iterations}

\item{Learningrate}{A symbolic description of model to be fitted}

\item{isSigmoid}{Used to select execution mode: Regression or Classification}
}
\value{
\code{neuralnet} returns an object of class \code{FLNnet}
}
\description{
\code{neuralnet} performs Neural Network on FLTable objects.
The DB Lytix function called is FLNNetUDT. Artificial neural networks are a family
of statistical learning algorithms inspired by biological neural networks
and are used to estimate or approximate transformations that depend on a
large number of inputs. Thesetransformation are then used to model the output.
In DB Lytix, neural network is implemented as a user-defined table function which takes
the input in deep format, the topography of the network along with some
hyper-parameters to calculate the neuron connection weights using the
back-propagation algorithm.
}
\section{Slots}{

\describe{
\item{\code{results}}{cache list of results computed}

\item{\code{table}}{Input data object}
}}

\examples{
tbl <- FLTable("tblwinetrain", obs_id_colname = "OBSID")
rtbl <- as.R(tbl)
rtbl <- rtbl[, -c(1)]
n <- names(rtbl)
f <- as.formula(paste("Wine_Type ~", paste(n[!n \%in\% "Wine_Type"], collapse = " + ")))
For 1 layer.
flmod <- neuralnet(f, data = tbl, hidden = c(5), layers = 1)
rmod <- neuralnet(f, data = rtbl, hidden = c( 5))
For 2 layer 
flmod <-neuralnet(f, data = tbl, hidden = c(10,5))
rmod <- neuralnet(f, data = rtbl, hidden = c(10, 5))
library(neuralnet)
flmod <- neuralnet(Wine_Type~.,data=tbl, hidden = c(10, 5))
flmod <- neuralnet(Wine_Type~ Alcohol + Ash,data=tbl)
rmod <- neuralnet(Wine_Type~ Alcohol + Ash,data=rtbl, hidden = c(5,5))

R Example:
library(MASS)
rdata <- Boston
n <- names(rdata)
f <- as.formula(paste("medv ~", paste(n[!n \%in\% "medv"], collapse = " + ")))
maxs <- apply(rdata, 2, max)
mins <- apply(rdata, 2, min)
rdata <- as.data.frame(scale(rdata, center = mins, scale = maxs - mins))
fltbl <- as.FL(rdata)
rmod <- neuralnet(f,data=rdata,hidden=c(5,3),linear.output=T)
flmod <- neuralnet(f, data = fltbl, hidden = c(5,3))
R example 2:
set.seed(100)
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
rtbl <- cbind(traininginput,trainingoutput)
colnames(rtbl) <- c("InputCol","OutputCol")
fltbl <- as.FL(rtbl)
rmod <- neuralnet(OutputCol~InputCol,data=rtbl,hidden=c(10),linear.output=T)
flmod <- neuralnet(OutputCol~InputCol,data=fltbl,hidden=c(10), IsSigmoid = 0, layers = 1)
}
\seealso{
\code{\link[neuralnet]{neuralnet}} for R reference implementation.
}
